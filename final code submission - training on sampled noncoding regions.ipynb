{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import path \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import collections\n",
    "import random\n",
    "import gffpandas.gffpandas as gffpd\n",
    "import random\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "directory = os.getcwd()\n",
    "folders = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [name for name in os.listdir(\"post_processed_data/\")]\n",
    "genomes.remove('.DS_Store')\n",
    "sorted_genomes = sorted(genomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4288"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "train_x = np.array([])\n",
    "train_y = np.array([])\n",
    "test_x = np.array([])\n",
    "test_y = np.array([])\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def read_fasta(dir_name, genome_name, file_name):\n",
    "    #'sampled_genomes_resampled/'\n",
    "    f=open(str(dir_name) + '/' + str(genome_name) + '/' + file_name,'r')\n",
    "    lines=f.readlines()\n",
    "\n",
    "    hre=re.compile('>(\\S+)')\n",
    "    lre=re.compile('^(\\S+)$')\n",
    "\n",
    "    gene={}\n",
    "\n",
    "    for line in lines:\n",
    "            outh = hre.search(line)\n",
    "            if outh:\n",
    "                    id=outh.group(1)\n",
    "            else:\n",
    "                    outl=lre.search(line)\n",
    "                    if(id in gene.keys()):\n",
    "                            gene[id] += outl.group(1)\n",
    "                    else:\n",
    "                            gene[id]  =outl.group(1)\n",
    "    return list(gene.values())\n",
    "\n",
    "def create_csv(dir_name, genome, coding_seqs, sampled_noncoding_seqs):\n",
    "    num_coding_seqs = len(coding_seqs)\n",
    "    num_noncoding_seqs = len(sampled_noncoding_seqs)\n",
    "    coding_indices = np.arange(0, num_coding_seqs, 1)\n",
    "    coding_groundtruth = np.arange(0, num_coding_seqs, 1)\n",
    "    coding_train = ['train'] * num_coding_seqs\n",
    "    noncoding_indices = np.arange(0, num_noncoding_seqs, 1)\n",
    "    noncoding_test = ['test'] * num_noncoding_seqs\n",
    "    noncoding_groundtruth = np.arange(0, num_noncoding_seqs, 1)\n",
    "    \n",
    "    data = {'sequence': coding_seqs, 'target': coding_groundtruth, 'set': coding_train, 'validation': [np.nan] * num_coding_seqs}\n",
    "    coding_df = pd.DataFrame(data, index=coding_indices)\n",
    "    coding_df.to_csv(dir_name + '/' + genome + '/debug_coding_train.csv')\n",
    "    \n",
    "    data = {'sequence': sampled_noncoding_seqs, 'target': noncoding_groundtruth, 'set': noncoding_test, 'validation': [np.nan] * num_noncoding_seqs}\n",
    "    noncoding_df = pd.DataFrame(data, index=noncoding_indices)\n",
    "    noncoding_df.to_csv(dir_name + '/' + genome + '/debug_noncoding_test.csv')\n",
    "    \n",
    "def find_first_index(lst, target):\n",
    "    \"\"\"\n",
    "    Finds the index of the first matching element in the given list.\n",
    "    If no match is found, returns -1.\n",
    "    \"\"\"\n",
    "    for i, item in enumerate(lst):\n",
    "        if item == target:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "    \n",
    "def create_dict(lst):\n",
    "    result = {element: [] for element in lst}\n",
    "    return result\n",
    "\n",
    "def filter_duplicate_subdirectories(directories):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where the keys are directory names and the values are lists of subdirectories,\n",
    "    filtered to exclude duplicates except for the first encounter of each subdirectory name\n",
    "    in the order of directories sorted in lexicographic order.\n",
    "    \"\"\"\n",
    "    filtered_directory_indices = create_dict(directories.keys())\n",
    "    filtered_directory_genes = create_dict(directories.keys())\n",
    "    subdirectory_set = set()\n",
    "    for directory_name in sorted(directories.keys()):\n",
    "        for i in range(len(directories[directory_name])):\n",
    "            if not directories[directory_name][i] in subdirectory_set:\n",
    "                filtered_directory_indices[directory_name].append(i)\n",
    "                filtered_directory_genes[directory_name].append(directories[directory_name][i])\n",
    "                subdirectory_set.add(directories[directory_name][i])\n",
    "            else:\n",
    "                continue\n",
    "    return filtered_directory_genes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = 'GCF_000021565.1_ASM2156v1'\n",
    "sequences = read_fasta('/Users/tonytu/Desktop/old_stuff/berkeley/fall2022/amiralilab/post_processed_data', genome, 'short.fasta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MECFNGNEWLKKSLEEIFTPPRENWDELRLWVYRFGDDWDIFLIELTIPKLLEEMSEK',\n",
       " 'MENSWWELAGIIFFSFMVITVALIWGLAIKASYNEEKQKKEEKQQ',\n",
       " 'MSVADIVILSLLVGGSVFYLYKKFRKDIQKGKCASCPVYGECESEKKV',\n",
       " 'MSIEQQVLEAMQKAGKPLRSGEIAELTGLDKKEVEKAIKKLKKEGKIESPKRCYYAPSG',\n",
       " 'MPEKVKDHLSNKKRKRTSGFLARKRTKSGRKILARRRRKGRKRIAIS',\n",
       " 'MNETVELIFTVVIFLLAVIVIVGLMVYWSKNNTVVDERDRKYYQKDKNDDINH',\n",
       " 'MPREIITLACTECKRKNYTTTKNKRKHTDRLELRKYCKFCRKHTLHREIK',\n",
       " 'MGLYDRDYMRERGKRPSPYKTDENKKLIIIAVISFILGFIAGKII',\n",
       " 'MRIKVKLVRGLAGKRKDQIKAVRSLGLKKVNDERILEKNPMVLGNINKVKHLIQVEEVE',\n",
       " 'MKVRSSVKKRCEKCRIIKRNGRIMVICENPRHKQKQG']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "coding_genes = []\n",
    "noncoding_genes = []\n",
    "positive_genomes = {}\n",
    "negative_genomes = {}\n",
    "for genome in genomes:\n",
    "    # adding a length constraint\n",
    "    length_upper_limit = 60\n",
    "    length_lower_limit = 0\n",
    "#     positive_testing_sequences = list(pd.read_csv('/Users/tonytu/Desktop/post_processed_data/' + genome + '/coding_train.csv')['sequence'])\n",
    "#     negative_testing_sequences = list(pd.read_csv('/Users/tonytu/Desktop/post_processed_data/' + genome + '/noncoding_test.csv')['sequence'])\n",
    "    positive_testing_sequences = list(pd.read_csv('post_processed_data/' + genome + '/coding_train.csv')['sequence'])\n",
    "    negative_testing_sequences = list(pd.read_csv('post_processed_data/' + genome + '/noncoding_test.csv')['sequence'])\n",
    "    positive_testing_sequences = [positive_testing_sequence for positive_testing_sequence in positive_testing_sequences if len(positive_testing_sequence) < 60]\n",
    "    negative_testing_sequences = [negative_testing_sequence for negative_testing_sequence in negative_testing_sequences if len(negative_testing_sequence) < 60]\n",
    "    coding_genes.extend(positive_testing_sequences)\n",
    "    noncoding_genes.extend(negative_testing_sequences)\n",
    "    \n",
    "    positive_genomes[genome] = positive_testing_sequences\n",
    "    negative_genomes[genome] = negative_testing_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 145232 coding regions, out of which 128615 are unique.\n",
      "In total, there are 145231 noncoding regions, out of which 143362 are unique.\n"
     ]
    }
   ],
   "source": [
    "print('In total, there are ' + str(len(coding_genes)) + ' coding regions, out of which ' + str(len(set(coding_genes))) + ' are unique.')\n",
    "print('In total, there are ' + str(len(noncoding_genes)) + ' noncoding regions, out of which ' + str(len(set(noncoding_genes))) + ' are unique.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "result = collections.Counter(coding_genes) & collections.Counter(noncoding_genes)\n",
    "intersected_list = list(result.elements())\n",
    "print(len(intersected_list))\n",
    "print(len(set(intersected_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing these from all datasets\n",
    "unique_intersected_list = set(intersected_list)\n",
    "for genome in genomes:\n",
    "    for gene in positive_genomes[genome]:\n",
    "        if gene in unique_intersected_list:\n",
    "            positive_genomes[genome].remove(gene)\n",
    "    for gene in negative_genomes[genome]:\n",
    "        if gene in unique_intersected_list:\n",
    "            negative_genomes[genome].remove(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering out sequences which are longer or equal to 60 AAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genome in genomes:\n",
    "    for gene in positive_genomes[genome]:\n",
    "        if len(gene) >= 60:\n",
    "            positive_genomes[genome].remove(gene)\n",
    "    for gene in negative_genomes[genome]:\n",
    "        if len(gene) >= 60:\n",
    "            negative_genomes[genome].remove(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering duplicates in lexicographical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duplicate_subdirectories(directories):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where the keys are directory names and the values are lists of subdirectories,\n",
    "    filtered to exclude duplicates except for the first encounter of each subdirectory name\n",
    "    in the order of directories sorted in lexicographic order.\n",
    "    \"\"\"\n",
    "    filtered_directory_indices = create_dict(directories.keys())\n",
    "    filtered_directory_genes = create_dict(directories.keys())\n",
    "    subdirectory_set = set()\n",
    "    for directory_name in sorted(directories.keys()):\n",
    "        for i in range(len(directories[directory_name])):\n",
    "            if not directories[directory_name][i] in subdirectory_set:\n",
    "                filtered_directory_indices[directory_name].append(i)\n",
    "                filtered_directory_genes[directory_name].append(directories[directory_name][i])\n",
    "                subdirectory_set.add(directories[directory_name][i])\n",
    "            else:\n",
    "                continue\n",
    "    return filtered_directory_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running filtering on all genomes\n",
    "positive_filtered_genes = filter_duplicate_subdirectories(positive_genomes)\n",
    "negative_filtered_genes = filter_duplicate_subdirectories(negative_genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 intersected sequences\n"
     ]
    }
   ],
   "source": [
    "#sanity check that there are no duplicates and no shared elements in coding regions and noncoding regions\n",
    "print('There are ' + str(len(collections.Counter(flatten(positive_filtered_genes.values())) & collections.Counter(flatten(negative_filtered_genes.values())))) + ' intersected sequences')\n",
    "assert(len(flatten(positive_filtered_genes.values())) == len(set(flatten(positive_filtered_genes.values()))))\n",
    "assert(len(flatten(negative_filtered_genes.values())) == len(set(flatten(negative_filtered_genes.values()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are, in total, 128578 coding regions\n",
      "There are, in total, 143325 noncoding regions\n"
     ]
    }
   ],
   "source": [
    "#data after filtering\n",
    "print('There are, in total, ' + str(len(flatten(positive_filtered_genes.values()))) + ' coding regions')\n",
    "print('There are, in total, ' + str(len(flatten(negative_filtered_genes.values()))) + ' noncoding regions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the indices:\n",
    "positive_filtered_genes_indices = {}\n",
    "negative_filtered_genes_indices = {}\n",
    "\n",
    "def indices_of_elements(list1, list2):\n",
    "    indices = []\n",
    "    for element in list1:\n",
    "        try:\n",
    "            index = list2.index(element)\n",
    "            indices.append(index)\n",
    "        except ValueError:\n",
    "            print('sequence not found!')\n",
    "            pass\n",
    "    return indices\n",
    "\n",
    "for genome in genomes:\n",
    "    positive_testing_sequences = list(pd.read_csv('post_processed_data/' + genome + '/coding_train.csv')['sequence'])\n",
    "    negative_testing_sequences = list(pd.read_csv('post_processed_data/' + genome + '/noncoding_test.csv')['sequence'])\n",
    "    \n",
    "    filtered_positive_genes = positive_filtered_genes[genome]\n",
    "    filtered_negative_genes = negative_filtered_genes[genome]\n",
    "    \n",
    "    positive_filtered_genes_indices[genome] = indices_of_elements(filtered_positive_genes, positive_testing_sequences)\n",
    "    negative_filtered_genes_indices[genome] = indices_of_elements(filtered_negative_genes, negative_testing_sequences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128578\n",
      "143325\n"
     ]
    }
   ],
   "source": [
    "coding_region_lengths = [len(coding_region) for coding_region in flatten(positive_filtered_genes.values())]\n",
    "noncoding_region_lengths = [len(noncoding_region) for noncoding_region in flatten(negative_filtered_genes.values())]\n",
    "print(len(coding_region_lengths))\n",
    "print(len(noncoding_region_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('Coding regions vs. sampled noncoding regions lengths distribution')\n",
    "axes[0].set_title('Coding regions')\n",
    "axes[1].set_title('Sampled noncoding regions')\n",
    "\n",
    "axes[0].set_xlabel('Sequence length')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].set_xlabel('Sequence length')\n",
    "axes[1].set_ylabel('Count')\n",
    "# plt.xlabel('Count')\n",
    "# plt.ylabel('Protein sequence length')\n",
    "\n",
    "pd.Series(coding_region_lengths).hist(bins=15, ax=axes[0])\n",
    "pd.Series(noncoding_region_lengths).hist(bins=15, ax=axes[1])\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('length_distribution.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading all embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train and test folders:\n",
    "MAX_FOLD = 10\n",
    "post_processed_data_PATH = 'post_processed_data'\n",
    "all_genomes = os.listdir(post_processed_data_PATH)\n",
    "all_genomes.remove('.DS_Store')\n",
    "\n",
    "\n",
    "def retrieve_train_test_folders(genomes, hold_out_index):\n",
    "    num_genomes = len(genomes)\n",
    "    if hold_out_index == MAX_FOLD - 1:\n",
    "        test_split = genomes[int((num_genomes//10) * hold_out_index): ]\n",
    "        train_split = list(set(genomes) - set(test_split))\n",
    "        assert len(train_split) + len(test_split) == num_genomes, \"numbers do not match up!\"\n",
    "        return train_split, test_split\n",
    "    test_split = genomes[int((num_genomes//10) * hold_out_index): int(num_genomes//10 * (hold_out_index + 1))]\n",
    "    train_split = list(set(genomes) - set(test_split))\n",
    "    assert len(train_split) + len(test_split) == num_genomes, \"numbers do not match up!\"\n",
    "    return train_split, test_split\n",
    "    \n",
    "train_genomes, test_genomes = retrieve_train_test_folders(all_genomes, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "def load_data(genomes):\n",
    "    all_x = np.array([])\n",
    "    all_y = np.array([])\n",
    "\n",
    "    random.seed(5)\n",
    "    torch.manual_seed(5)\n",
    "    for genome in genomes:\n",
    "        \n",
    "        positive_indices = np.array(positive_filtered_genes_indices[genome]) \n",
    "        negative_indices = np.array(negative_filtered_genes_indices[genome])\n",
    "\n",
    "        if positive_indices.shape[0] != 0:\n",
    "            genome_train_coding_embeddings = torch.load('post_processed_data/' + genome + '/coding_train_emb/train_mean.pt')\n",
    "            genome_train_coding_labels = np.ones(genome_train_coding_embeddings.shape[0])[positive_indices]\n",
    "            genome_train_coding_embeddings = genome_train_coding_embeddings[positive_indices]\n",
    "            assert genome_train_coding_embeddings.shape[0] == len(positive_indices)\n",
    "\n",
    "        if negative_indices.shape[0] != 0:\n",
    "            genome_train_noncoding_embeddings = torch.load('post_processed_data/' + genome + '/noncoding_test_emb/train_mean.pt')\n",
    "            genome_train_noncoding_labels = np.zeros(genome_train_noncoding_embeddings.shape[0])[negative_indices]\n",
    "            genome_train_noncoding_embeddings = genome_train_noncoding_embeddings[negative_indices]\n",
    "            assert genome_train_noncoding_embeddings.shape[0] == len(negative_indices)\n",
    "\n",
    "        if all_x.shape[0] == 0:\n",
    "            all_x = genome_train_coding_embeddings\n",
    "            all_y = genome_train_coding_labels\n",
    "            all_x = np.concatenate((all_x, genome_train_noncoding_embeddings), axis=0)\n",
    "            all_y = np.concatenate((all_y, genome_train_noncoding_labels), axis=0)\n",
    "            continue\n",
    "\n",
    "        if positive_indices.shape[0] != 0:\n",
    "            all_x = np.concatenate((all_x, genome_train_coding_embeddings), axis=0)\n",
    "            all_y = np.concatenate((all_y, genome_train_coding_labels), axis=0)\n",
    "        \n",
    "        if negative_indices.shape[0] != 0:\n",
    "            all_x = np.concatenate((all_x, genome_train_noncoding_embeddings), axis=0)\n",
    "            all_y = np.concatenate((all_y, genome_train_noncoding_labels), axis=0)\n",
    "    return all_x, all_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_folds_embs, all_data_folds_labels = [], []\n",
    "MAX_FOLD = 10\n",
    "for i in range(0, MAX_FOLD, 1):\n",
    "    train_split, test_split = retrieve_train_test_folders(genomes, i)\n",
    "    embs, labels = load_data(test_split)\n",
    "    all_data_folds_embs.append(embs)\n",
    "    all_data_folds_labels.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after applying filters, some of the genomes have no coding regions or noncoding regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check that the dimension of the loaded data is equal to the dimension of the indices in the dictionary\n",
    "assert np.vstack(all_data_folds_embs).shape[0] == len(flatten(positive_filtered_genes.values())) + len(flatten(negative_filtered_genes.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_018406645.1_ASM1840664v1\n",
      "none!\n",
      "GCF_017896245.1_ASM1789624v1\n",
      "none!\n",
      "GCF_002850495.1_ASM285049v1\n",
      "none!\n",
      "GCF_018467135.1_ASM1846713v1\n",
      "none!\n",
      "GCF_011455875.1_ASM1145587v1\n",
      "none!\n",
      "GCF_002804025.1_ASM280402v1\n",
      "none!\n"
     ]
    }
   ],
   "source": [
    "empty_positive_genomes = []\n",
    "for genome in genomes:\n",
    "    if not positive_filtered_genes_indices[genome]:\n",
    "        empty_positive_genomes.append(genome)\n",
    "        print(genome)\n",
    "        print('none!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_000287275.1_ASM28727v1\n",
      "none!\n",
      "GCF_001447915.1_ASM144791v1\n",
      "none!\n"
     ]
    }
   ],
   "source": [
    "empty_negative_genomes = []\n",
    "for genome in genomes:\n",
    "    if not negative_filtered_genes_indices[genome]:\n",
    "        empty_negative_genomes.append(genome)\n",
    "        print(genome)\n",
    "        print('none!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading classifier:\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,input_shape):\n",
    "    super(Net,self).__init__()\n",
    "    #input embedding: 1280\n",
    "    self.fc1 = nn.Linear(input_shape,32)\n",
    "    self.fc2 = nn.Linear(32,64)\n",
    "    self.fc3 = nn.Linear(64,1)\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = torch.sigmoid(self.fc3(x))\n",
    "    return x\n",
    "\n",
    "class Net1(nn.Module):\n",
    "  def __init__(self,input_shape):\n",
    "    super(Net1,self).__init__()\n",
    "    #input embedding: 1280\n",
    "    self.fc1 = nn.Linear(input_shape,32)\n",
    "    self.fc2 = nn.Linear(32,64)\n",
    "    self.fc3 = nn.Linear(64,128)\n",
    "    self.fc4 = nn.Linear(128,64)\n",
    "    self.fc5 = nn.Linear(64,32)\n",
    "    self.fc6 = nn.Linear(32,1)\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc6.weight)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = torch.relu(self.fc3(x))\n",
    "    x = torch.relu(self.fc4(x))\n",
    "    x = torch.relu(self.fc5(x))\n",
    "    x = torch.sigmoid(self.fc6(x))\n",
    "    return x\n",
    "\n",
    "class Net3(nn.Module):\n",
    "  def __init__(self,input_shape):\n",
    "    super(Net3,self).__init__()\n",
    "    #input embedding: 1280\n",
    "    self.fc1 = nn.Linear(input_shape,1)\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = torch.sigmoid(self.fc1(x))\n",
    "    return x\n",
    "\n",
    "class Net4(nn.Module):\n",
    "  def __init__(self,input_shape):\n",
    "    super(Net4,self).__init__()\n",
    "    #input embedding: 1280\n",
    "    self.fc1 = nn.Linear(input_shape,128)\n",
    "    self.fc2 = nn.Linear(128,256)\n",
    "    self.fc3 = nn.Linear(256,512)\n",
    "    self.fc4 = nn.Linear(512,256)\n",
    "    self.fc5 = nn.Linear(256,128)\n",
    "    self.fc6 = nn.Linear(128,64)\n",
    "    self.fc7 = nn.Linear(64,32)\n",
    "    self.fc8 = nn.Linear(32,1)\n",
    "    torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc6.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc7.weight)\n",
    "    torch.nn.init.xavier_uniform_(self.fc8.weight)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = torch.relu(self.fc3(x))\n",
    "    x = torch.relu(self.fc4(x))\n",
    "    x = torch.relu(self.fc5(x))\n",
    "    x = torch.relu(self.fc6(x))\n",
    "    x = torch.relu(self.fc7(x))\n",
    "    x = torch.sigmoid(self.fc8(x))\n",
    "    return x\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = [item for sublist in l for item in sublist]\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245544, 1280)\n",
      "(245544,)\n",
      "(26359, 1280)\n",
      "(26359,)\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_data(all_data_folds_embs, all_data_folds_labels, fold):\n",
    "    test_split = [fold]\n",
    "    train_split = list(set(list(range(10))) - set([fold]))\n",
    "    train_x = np.vstack([all_data_folds_embs[i] for i in train_split])\n",
    "    train_y = np.concatenate([all_data_folds_labels[i] for i in train_split])\n",
    "    test_x = np.vstack([all_data_folds_embs[i] for i in test_split])\n",
    "    test_y = np.concatenate([all_data_folds_labels[i] for i in test_split])\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = create_train_test_data(all_data_folds_embs, all_data_folds_labels, 0)\n",
    "\n",
    "#checking dimensions:\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly shuffling train_x, train_y and their corresponding labels\n",
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "training_indices = np.arange(train_x.shape[0])\n",
    "test_indices = np.arange(test_x.shape[0])\n",
    "np.random.shuffle(training_indices)\n",
    "np.random.shuffle(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x[training_indices]\n",
    "train_y = train_y[training_indices]\n",
    "test_x = test_x[test_indices]\n",
    "test_y = test_y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x,dtype=torch.float32)\n",
    "    self.y = torch.tensor(y,dtype=torch.float32)\n",
    "    self.length = self.x.shape[0]\n",
    " \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "trainset = dataset(train_x, train_y)\n",
    "#DataLoader\n",
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "learning_rate = 0.01\n",
    "epochs = 300\n",
    "# Model , Optimizer, Loss\n",
    "ecoli_model = Net4(input_shape=train_x.shape[1])\n",
    "optimizer = torch.optim.SGD(ecoli_model.parameters(),lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward loop\n",
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "losses = []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "  for j,(x_train,y_train) in enumerate(trainloader):\n",
    "    \n",
    "    #calculate output\n",
    "    output = ecoli_model(x_train)\n",
    " \n",
    "    #calculate loss\n",
    "    loss = loss_fn(output,y_train.reshape(-1,1))\n",
    " \n",
    "    #accuracy\n",
    "    predicted = ecoli_model(torch.tensor(x_train,dtype=torch.float32))\n",
    "    acc = (predicted.reshape(-1).detach().numpy().round() == np.array(y_train)).mean()\n",
    "    #backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if i%50 == 0:\n",
    "    losses.append(loss)\n",
    "    accur.append(acc)\n",
    "    print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonytu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\tloss : 0.17696475982666016\t accuracy : 0.95\n",
      "epoch 50\tloss : 0.14576508104801178\t accuracy : 0.925\n",
      "epoch 100\tloss : 0.13810546696186066\t accuracy : 0.925\n",
      "epoch 150\tloss : 0.1344241350889206\t accuracy : 0.95\n",
      "epoch 200\tloss : 0.1285872459411621\t accuracy : 0.95\n",
      "epoch 250\tloss : 0.11938326060771942\t accuracy : 0.95\n",
      "epoch 0\tloss : 0.24542240798473358\t accuracy : 0.8727272727272727\n",
      "epoch 50\tloss : 0.16304725408554077\t accuracy : 0.9272727272727272\n",
      "epoch 100\tloss : 0.1430915892124176\t accuracy : 0.9272727272727272\n",
      "epoch 150\tloss : 0.14132927358150482\t accuracy : 0.9454545454545454\n",
      "epoch 200\tloss : 0.13264790177345276\t accuracy : 0.9454545454545454\n",
      "epoch 250\tloss : 0.10950611531734467\t accuracy : 0.9818181818181818\n",
      "epoch 0\tloss : 0.06013019010424614\t accuracy : 0.95\n",
      "epoch 50\tloss : 0.03936905413866043\t accuracy : 1.0\n",
      "epoch 100\tloss : 0.03182206302881241\t accuracy : 1.0\n",
      "epoch 150\tloss : 0.03195275738835335\t accuracy : 1.0\n",
      "epoch 200\tloss : 0.03518430143594742\t accuracy : 1.0\n",
      "epoch 250\tloss : 0.03285235911607742\t accuracy : 1.0\n",
      "epoch 0\tloss : 0.16739515960216522\t accuracy : 0.9285714285714286\n",
      "epoch 50\tloss : 0.1298239678144455\t accuracy : 1.0\n",
      "epoch 100\tloss : 0.12364654242992401\t accuracy : 1.0\n",
      "epoch 150\tloss : 0.12803514301776886\t accuracy : 1.0\n",
      "epoch 200\tloss : 0.09696947783231735\t accuracy : 1.0\n",
      "epoch 250\tloss : 0.08001398295164108\t accuracy : 1.0\n",
      "epoch 0\tloss : 0.1779150366783142\t accuracy : 0.9\n",
      "epoch 50\tloss : 0.14847931265830994\t accuracy : 0.9\n",
      "epoch 100\tloss : 0.15245410799980164\t accuracy : 0.9\n",
      "epoch 150\tloss : 0.15404851734638214\t accuracy : 0.9\n",
      "epoch 200\tloss : 0.13731686770915985\t accuracy : 0.9\n",
      "epoch 250\tloss : 0.10184743255376816\t accuracy : 0.9\n",
      "epoch 0\tloss : 0.028687840327620506\t accuracy : 1.0\n",
      "epoch 50\tloss : 0.018230149522423744\t accuracy : 1.0\n",
      "epoch 100\tloss : 0.01144245732575655\t accuracy : 1.0\n",
      "epoch 150\tloss : 0.007118232548236847\t accuracy : 1.0\n",
      "epoch 200\tloss : 0.005385604687035084\t accuracy : 1.0\n",
      "epoch 250\tloss : 0.007016936782747507\t accuracy : 1.0\n",
      "epoch 0\tloss : 0.08680141717195511\t accuracy : 1.0\n",
      "epoch 50\tloss : 0.09348164498806\t accuracy : 1.0\n",
      "epoch 100\tloss : 0.07931260019540787\t accuracy : 1.0\n",
      "epoch 150\tloss : 0.0941402018070221\t accuracy : 1.0\n",
      "epoch 200\tloss : 0.06865277141332626\t accuracy : 1.0\n",
      "epoch 250\tloss : 0.05231573432683945\t accuracy : 1.0\n",
      "epoch 0\tloss : 0.19093111157417297\t accuracy : 0.9423076923076923\n",
      "epoch 50\tloss : 0.13245831429958344\t accuracy : 0.9615384615384616\n",
      "epoch 100\tloss : 0.12610073387622833\t accuracy : 0.9615384615384616\n",
      "epoch 150\tloss : 0.11777892708778381\t accuracy : 0.9615384615384616\n",
      "epoch 200\tloss : 0.10851751267910004\t accuracy : 0.9615384615384616\n",
      "epoch 250\tloss : 0.09367197006940842\t accuracy : 0.9807692307692307\n",
      "epoch 0\tloss : 0.21052655577659607\t accuracy : 0.9411764705882353\n",
      "epoch 50\tloss : 0.2236715704202652\t accuracy : 0.9019607843137255\n",
      "epoch 100\tloss : 0.227963387966156\t accuracy : 0.9019607843137255\n",
      "epoch 150\tloss : 0.2132292240858078\t accuracy : 0.9019607843137255\n",
      "epoch 200\tloss : 0.2017964869737625\t accuracy : 0.9215686274509803\n",
      "epoch 250\tloss : 0.18997931480407715\t accuracy : 0.9411764705882353\n",
      "epoch 0\tloss : 0.5582899451255798\t accuracy : 0.7647058823529411\n",
      "epoch 50\tloss : 0.43690595030784607\t accuracy : 0.7647058823529411\n",
      "epoch 100\tloss : 0.39718231558799744\t accuracy : 0.7647058823529411\n",
      "epoch 150\tloss : 0.3905550241470337\t accuracy : 0.7647058823529411\n",
      "epoch 200\tloss : 0.28762468695640564\t accuracy : 0.8235294117647058\n",
      "epoch 250\tloss : 0.26375511288642883\t accuracy : 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 10, 1):\n",
    "    train_x, train_y, test_x, test_y = create_train_test_data(all_data_folds_embs, all_data_folds_labels, epoch)\n",
    "    \n",
    "    random.seed(5)\n",
    "    torch.manual_seed(5)\n",
    "    training_indices = np.arange(train_x.shape[0])\n",
    "    test_indices = np.arange(test_x.shape[0])\n",
    "    np.random.shuffle(training_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "    train_x = train_x[training_indices]\n",
    "    train_y = train_y[training_indices]\n",
    "    test_x = test_x[test_indices]\n",
    "    test_y = test_y[test_indices]\n",
    "    \n",
    "    trainset = dataset(train_x, train_y)\n",
    "    #DataLoader\n",
    "    trainloader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
    "    \n",
    "    #hyper parameters\n",
    "    random.seed(5)\n",
    "    torch.manual_seed(5)\n",
    "    learning_rate = 0.01\n",
    "    epochs = 300\n",
    "    # Model , Optimizer, Loss\n",
    "    ecoli_model = Net1(input_shape=train_x.shape[1])\n",
    "    optimizer = torch.optim.SGD(ecoli_model.parameters(),lr=learning_rate)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    \n",
    "    random.seed(5)\n",
    "    torch.manual_seed(5)\n",
    "    losses = []\n",
    "    accur = []\n",
    "    for i in range(epochs):\n",
    "      for j,(x_train,y_train) in enumerate(trainloader):\n",
    "\n",
    "        #calculate output\n",
    "        output = ecoli_model(x_train)\n",
    "\n",
    "        #calculate loss\n",
    "        loss = loss_fn(output,y_train.reshape(-1,1))\n",
    "\n",
    "        #accuracy\n",
    "        predicted = ecoli_model(torch.tensor(x_train,dtype=torch.float32))\n",
    "        acc = (predicted.reshape(-1).detach().numpy().round() == np.array(y_train)).mean()\n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      if i%50 == 0:\n",
    "        losses.append(loss)\n",
    "        accur.append(acc)\n",
    "        print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))\n",
    "    \n",
    "    #saving model\n",
    "    PATH = \"/Users/tonytu/desktop/old_stuff/berkeley/fall2022/amiralilab/final_ten_fold_cross_validation_models/six_layer_fold_\" + str(epoch) + \"_genomes.pt\"\n",
    "    torch.save(ecoli_model, PATH)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluating model performance (aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "total samples: 26359\n",
      "TP: 11295\n",
      "FP: 593\n",
      "TN: 13380\n",
      "FN: 1091\n",
      "accuracy: 0.936112902613908\n",
      "precision: 0.9501177658142664\n",
      "recall: 0.9119166801227192\n",
      "F1: 0.9306253604679905\n",
      "\n",
      "\n",
      "fold 1\n",
      "total samples: 28136\n",
      "TP: 12162\n",
      "FP: 900\n",
      "TN: 13976\n",
      "FN: 1098\n",
      "accuracy: 0.9289877736707421\n",
      "precision: 0.9310978410656867\n",
      "recall: 0.9171945701357466\n",
      "F1: 0.9240939138363347\n",
      "\n",
      "\n",
      "fold 2\n",
      "total samples: 30155\n",
      "TP: 13216\n",
      "FP: 1047\n",
      "TN: 14780\n",
      "FN: 1112\n",
      "accuracy: 0.9284032498756425\n",
      "precision: 0.9265932833204795\n",
      "recall: 0.9223897264098269\n",
      "F1: 0.9244867265922843\n",
      "\n",
      "\n",
      "fold 3\n",
      "total samples: 27793\n",
      "TP: 12172\n",
      "FP: 656\n",
      "TN: 13928\n",
      "FN: 1037\n",
      "accuracy: 0.9390853812110963\n",
      "precision: 0.9488618646710321\n",
      "recall: 0.9214929214929215\n",
      "F1: 0.9349771479049045\n",
      "\n",
      "\n",
      "fold 4\n",
      "total samples: 26517\n",
      "TP: 11761\n",
      "FP: 863\n",
      "TN: 13014\n",
      "FN: 879\n",
      "accuracy: 0.9343062940754987\n",
      "precision: 0.9316381495564005\n",
      "recall: 0.9304588607594937\n",
      "F1: 0.9310481317289423\n",
      "\n",
      "\n",
      "fold 5\n",
      "total samples: 27544\n",
      "TP: 12336\n",
      "FP: 1063\n",
      "TN: 13546\n",
      "FN: 599\n",
      "accuracy: 0.9396601800755155\n",
      "precision: 0.9206657213224868\n",
      "recall: 0.9536915345960572\n",
      "F1: 0.936887673729779\n",
      "\n",
      "\n",
      "fold 6\n",
      "total samples: 25298\n",
      "TP: 11293\n",
      "FP: 978\n",
      "TN: 12355\n",
      "FN: 672\n",
      "accuracy: 0.9347774527630642\n",
      "precision: 0.9202998940591639\n",
      "recall: 0.9438361888842457\n",
      "F1: 0.9319194586565439\n",
      "\n",
      "\n",
      "fold 7\n",
      "total samples: 27371\n",
      "TP: 11944\n",
      "FP: 734\n",
      "TN: 13646\n",
      "FN: 1047\n",
      "accuracy: 0.9349311314895327\n",
      "precision: 0.9421044328758479\n",
      "recall: 0.9194057424370718\n",
      "F1: 0.9306166971833729\n",
      "\n",
      "\n",
      "fold 8\n",
      "total samples: 26604\n",
      "TP: 11740\n",
      "FP: 670\n",
      "TN: 13354\n",
      "FN: 840\n",
      "accuracy: 0.9432416178018344\n",
      "precision: 0.9460112812248187\n",
      "recall: 0.9332273449920508\n",
      "F1: 0.9395758303321329\n",
      "\n",
      "\n",
      "fold 9\n",
      "total samples: 26126\n",
      "TP: 11433\n",
      "FP: 1524\n",
      "TN: 12318\n",
      "FN: 851\n",
      "accuracy: 0.9090943887315318\n",
      "precision: 0.8823801805973605\n",
      "recall: 0.9307228915662651\n",
      "F1: 0.9059070559803494\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies, precisions, recalls, F1s = [], [], [], []\n",
    "for i in range(10):\n",
    "    print(\"fold \" + str(i))\n",
    "    # PATH = \"/Users/tonytu/desktop/old_stuff/berkeley/fall2022/amiralilab/final_models_with_42_held_out/six_layer_4246_genomes.pt\"\n",
    "    PATH = \"final_ten_fold_cross_validation_models/six_layer_fold_\" + str(i) + \"_genomes.pt\"\n",
    "#     PATH = \"/Users/tonytu/desktop/old_stuff/berkeley/fall2022/amiralilab/all_available_data_final_ten_fold_cross_validation_models/six_layer_fold_\" + str(i) + \"_genomes.pt\"\n",
    "    ecoli_model = torch.load(PATH)\n",
    "    ecoli_model.eval()\n",
    "    train_x, train_y, test_x, test_y = create_train_test_data(all_data_folds_embs, all_data_folds_labels, i)\n",
    "    test_output_raw = ecoli_model(torch.Tensor(test_x))\n",
    "    test_output = test_output_raw.round()\n",
    "    accuracy, precision, recall, f1 = perf_measure(list(test_y), list(test_output.detach().numpy()))\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    F1s.append(f1)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "total samples: 26359\n",
      "TP: 9839\n",
      "FP: 190\n",
      "TN: 13783\n",
      "FN: 2547\n",
      "accuracy: 0.8961644978944573\n",
      "precision: 0.981054940672051\n",
      "recall: 0.7943646051994186\n",
      "F1: 0.8778942672317644\n",
      "\n",
      "\n",
      "fold 1\n",
      "total samples: 28136\n",
      "TP: 10183\n",
      "FP: 252\n",
      "TN: 14624\n",
      "FN: 3077\n",
      "accuracy: 0.8816818311060562\n",
      "precision: 0.9758505031145185\n",
      "recall: 0.767948717948718\n",
      "F1: 0.8595062249419709\n",
      "\n",
      "\n",
      "fold 2\n",
      "total samples: 30155\n",
      "TP: 11165\n",
      "FP: 295\n",
      "TN: 15532\n",
      "FN: 3163\n",
      "accuracy: 0.8853258166141602\n",
      "precision: 0.9742582897033158\n",
      "recall: 0.7792434394193188\n",
      "F1: 0.8659066232356134\n",
      "\n",
      "\n",
      "fold 3\n",
      "total samples: 27793\n",
      "TP: 10764\n",
      "FP: 271\n",
      "TN: 14313\n",
      "FN: 2445\n",
      "accuracy: 0.9022775519015579\n",
      "precision: 0.9754417761667422\n",
      "recall: 0.8148989325459913\n",
      "F1: 0.8879722818016829\n",
      "\n",
      "\n",
      "fold 4\n",
      "total samples: 26517\n",
      "TP: 10078\n",
      "FP: 204\n",
      "TN: 13673\n",
      "FN: 2562\n",
      "accuracy: 0.8956895576422672\n",
      "precision: 0.9801595020424042\n",
      "recall: 0.7973101265822785\n",
      "F1: 0.8793299014047641\n",
      "\n",
      "\n",
      "fold 5\n",
      "total samples: 27544\n",
      "TP: 10763\n",
      "FP: 232\n",
      "TN: 14377\n",
      "FN: 2172\n",
      "accuracy: 0.9127214638396747\n",
      "precision: 0.9788994997726239\n",
      "recall: 0.8320834943950521\n",
      "F1: 0.8995403259506896\n",
      "\n",
      "\n",
      "fold 6\n",
      "total samples: 25298\n",
      "TP: 10152\n",
      "FP: 267\n",
      "TN: 13066\n",
      "FN: 1813\n",
      "accuracy: 0.9177800616649537\n",
      "precision: 0.9743737402821768\n",
      "recall: 0.8484747179272879\n",
      "F1: 0.9070764832022874\n",
      "\n",
      "\n",
      "fold 7\n",
      "total samples: 27371\n",
      "TP: 10131\n",
      "FP: 210\n",
      "TN: 14170\n",
      "FN: 2860\n",
      "accuracy: 0.8878374922363085\n",
      "precision: 0.9796924862199013\n",
      "recall: 0.7798475867908552\n",
      "F1: 0.8684210526315791\n",
      "\n",
      "\n",
      "fold 8\n",
      "total samples: 26604\n",
      "TP: 10034\n",
      "FP: 200\n",
      "TN: 13824\n",
      "FN: 2546\n",
      "accuracy: 0.8967824387310179\n",
      "precision: 0.9804572991987492\n",
      "recall: 0.7976152623211447\n",
      "F1: 0.8796353116507407\n",
      "\n",
      "\n",
      "fold 9\n",
      "total samples: 26126\n",
      "TP: 9541\n",
      "FP: 147\n",
      "TN: 13695\n",
      "FN: 2743\n",
      "accuracy: 0.8893822246038429\n",
      "precision: 0.9848265895953757\n",
      "recall: 0.7767014001953761\n",
      "F1: 0.8684689604951757\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracies, precisions, recalls, F1s = [], [], [], []\n",
    "for i in range(10):\n",
    "    print(\"fold \" + str(i))\n",
    "    # PATH = \"/Users/tonytu/desktop/old_stuff/berkeley/fall2022/amiralilab/final_models_with_42_held_out/six_layer_4246_genomes.pt\"\n",
    "#     PATH = \"/Users/tonytu/desktop/old_stuff/berkeley/fall2022/amiralilab/final_ten_fold_cross_validation_models/six_layer_fold_\" + str(i) + \"_genomes.pt\"\n",
    "    PATH = \"all_available_data_final_ten_fold_cross_validation_models/six_layer_fold_\" + str(i) + \"_genomes.pt\"\n",
    "    ecoli_model = torch.load(PATH)\n",
    "    ecoli_model.eval()\n",
    "    train_x, train_y, test_x, test_y = create_train_test_data(all_data_folds_embs, all_data_folds_labels, i)\n",
    "    test_output_raw = ecoli_model(torch.Tensor(test_x))\n",
    "    test_output = test_output_raw.round()\n",
    "    accuracy, precision, recall, f1 = perf_measure(list(test_y), list(test_output.detach().numpy()))\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    F1s.append(f1)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965642936234296\n",
      "0.9785014626767857\n",
      "0.7988488283325441\n",
      "0.8793751432546267\n",
      "\n",
      "\n",
      "0.01104675112425346\n",
      "0.003257464032761391\n",
      "0.02457563668818191\n",
      "0.014371096748860793\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracies))\n",
    "print(np.mean(precisions))\n",
    "print(np.mean(recalls))\n",
    "print(np.mean(F1s))\n",
    "\n",
    "print('\\n')\n",
    "print(np.std(accuracies))\n",
    "print(np.std(precisions))\n",
    "print(np.std(recalls))\n",
    "print(np.std(F1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_raw = ecoli_model(torch.Tensor(test_x))\n",
    "test_output = test_output_raw.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "actual = numpy.random.binomial(1,.9,size = 1000)\n",
    "predicted = numpy.random.binomial(1,.9,size = 1000)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(list(test_y), list(test_output.detach().numpy()))\n",
    "# confusion_matrix = metrics.confusion_matrix(list(test_y), list(a))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "# cm_display.set_ticklabels_format(\"d\")\n",
    "# np.set_printoptions(suppress=True) # disable scientific notation\n",
    "cm_display.plot(cmap=\"Blues\", values_format='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "    print(\"total samples: \" + str(len(y_actual)))\n",
    "    print(\"TP: \" + str(TP))\n",
    "    print(\"FP: \" + str(FP))\n",
    "    print(\"TN: \" + str(TN))\n",
    "    print(\"FN: \" + str(FN))\n",
    "    accuracy = accuracy_score(y_actual, y_hat)\n",
    "    precision = precision_score(y_actual, y_hat)\n",
    "    recall = recall_score(y_actual, y_hat)\n",
    "    f1 = f1_score(y_actual, y_hat)\n",
    "    print(\"accuracy: \" + str(accuracy))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    print(\"F1: \" + str(f1))\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 26359\n",
      "TP: 11285\n",
      "FP: 869\n",
      "TN: 13104\n",
      "FN: 1101\n",
      "accuracy: 0.9252627186160325\n",
      "precision: 0.9285009050518348\n",
      "recall: 0.9111093169707735\n",
      "F1: 0.9197229013854931\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = perf_measure(list(test_y), list(test_output.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating genome by genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_000283915.1_ASM28391v1\n",
      "98\n",
      "48.0\n",
      "50.0\n",
      "[9, 21]\n",
      "total samples: 98\n",
      "TP: 27\n",
      "FP: 2\n",
      "TN: 48\n",
      "FN: 21\n",
      "accuracy: 0.7653061224489796\n",
      "precision: 0.9310344827586207\n",
      "recall: 0.5625\n",
      "F1: 0.7012987012987013\n",
      "GCF_002056795.1_ASM205679v1\n",
      "66\n",
      "33.0\n",
      "33.0\n",
      "[3, 6, 10, 13, 25]\n",
      "total samples: 66\n",
      "TP: 32\n",
      "FP: 5\n",
      "TN: 28\n",
      "FN: 1\n",
      "accuracy: 0.9090909090909091\n",
      "precision: 0.8648648648648649\n",
      "recall: 0.9696969696969697\n",
      "F1: 0.9142857142857143\n",
      "GCF_009734425.1_ASM973442v1\n",
      "42\n",
      "20.0\n",
      "22.0\n",
      "[8]\n",
      "total samples: 42\n",
      "TP: 20\n",
      "FP: 1\n",
      "TN: 21\n",
      "FN: 0\n",
      "accuracy: 0.9761904761904762\n",
      "precision: 0.9523809523809523\n",
      "recall: 1.0\n",
      "F1: 0.975609756097561\n",
      "GCF_003097575.1_ASM309757v1\n",
      "31\n",
      "16.0\n",
      "15.0\n",
      "[]\n",
      "total samples: 31\n",
      "TP: 14\n",
      "FP: 0\n",
      "TN: 15\n",
      "FN: 2\n",
      "accuracy: 0.9354838709677419\n",
      "precision: 1.0\n",
      "recall: 0.875\n",
      "F1: 0.9333333333333333\n",
      "GCF_900476035.1_53694_C01\n",
      "36\n",
      "16.0\n",
      "20.0\n",
      "[]\n",
      "total samples: 36\n",
      "TP: 15\n",
      "FP: 0\n",
      "TN: 20\n",
      "FN: 1\n",
      "accuracy: 0.9722222222222222\n",
      "precision: 1.0\n",
      "recall: 0.9375\n",
      "F1: 0.967741935483871\n",
      "GCF_007750855.1_ASM775085v1\n",
      "30\n",
      "15.0\n",
      "15.0\n",
      "[0]\n",
      "total samples: 30\n",
      "TP: 14\n",
      "FP: 1\n",
      "TN: 14\n",
      "FN: 1\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 0.9333333333333333\n",
      "recall: 0.9333333333333333\n",
      "F1: 0.9333333333333333\n",
      "GCF_001858005.1_ASM185800v1\n",
      "33\n",
      "14.0\n",
      "19.0\n",
      "[18]\n",
      "total samples: 33\n",
      "TP: 13\n",
      "FP: 1\n",
      "TN: 18\n",
      "FN: 1\n",
      "accuracy: 0.9393939393939394\n",
      "precision: 0.9285714285714286\n",
      "recall: 0.9285714285714286\n",
      "F1: 0.9285714285714286\n",
      "GCF_025118245.1_ASM2511824v1\n",
      "75\n",
      "34.0\n",
      "41.0\n",
      "[]\n",
      "total samples: 75\n",
      "TP: 30\n",
      "FP: 0\n",
      "TN: 41\n",
      "FN: 4\n",
      "accuracy: 0.9466666666666667\n",
      "precision: 1.0\n",
      "recall: 0.8823529411764706\n",
      "F1: 0.9375\n",
      "GCF_019141525.1_ASM1914152v1\n",
      "67\n",
      "27.0\n",
      "40.0\n",
      "[]\n",
      "total samples: 67\n",
      "TP: 25\n",
      "FP: 0\n",
      "TN: 40\n",
      "FN: 2\n",
      "accuracy: 0.9701492537313433\n",
      "precision: 1.0\n",
      "recall: 0.9259259259259259\n",
      "F1: 0.9615384615384615\n",
      "GCF_020097615.1_ASM2009761v1\n",
      "25\n",
      "11.0\n",
      "14.0\n",
      "[]\n",
      "total samples: 25\n",
      "TP: 11\n",
      "FP: 0\n",
      "TN: 14\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_010727605.1_ASM1072760v1\n",
      "61\n",
      "28.0\n",
      "33.0\n",
      "[29]\n",
      "total samples: 61\n",
      "TP: 27\n",
      "FP: 1\n",
      "TN: 32\n",
      "FN: 1\n",
      "accuracy: 0.9672131147540983\n",
      "precision: 0.9642857142857143\n",
      "recall: 0.9642857142857143\n",
      "F1: 0.9642857142857143\n",
      "GCF_009708215.1_ASM970821v1\n",
      "48\n",
      "24.0\n",
      "24.0\n",
      "[]\n",
      "total samples: 48\n",
      "TP: 23\n",
      "FP: 0\n",
      "TN: 24\n",
      "FN: 1\n",
      "accuracy: 0.9791666666666666\n",
      "precision: 1.0\n",
      "recall: 0.9583333333333334\n",
      "F1: 0.9787234042553191\n",
      "GCF_001007875.1_ASM100787v1\n",
      "26\n",
      "13.0\n",
      "13.0\n",
      "[]\n",
      "total samples: 26\n",
      "TP: 13\n",
      "FP: 0\n",
      "TN: 13\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_001880225.1_ASM188022v1\n",
      "21\n",
      "10.0\n",
      "11.0\n",
      "[4, 7]\n",
      "total samples: 21\n",
      "TP: 8\n",
      "FP: 2\n",
      "TN: 9\n",
      "FN: 2\n",
      "accuracy: 0.8095238095238095\n",
      "precision: 0.8\n",
      "recall: 0.8\n",
      "F1: 0.8000000000000002\n",
      "GCF_000025485.1_ASM2548v1\n",
      "68\n",
      "34.0\n",
      "34.0\n",
      "[33]\n",
      "total samples: 68\n",
      "TP: 33\n",
      "FP: 1\n",
      "TN: 33\n",
      "FN: 1\n",
      "accuracy: 0.9705882352941176\n",
      "precision: 0.9705882352941176\n",
      "recall: 0.9705882352941176\n",
      "F1: 0.9705882352941176\n",
      "GCF_008806995.1_ASM880699v1\n",
      "34\n",
      "15.0\n",
      "19.0\n",
      "[]\n",
      "total samples: 34\n",
      "TP: 15\n",
      "FP: 0\n",
      "TN: 19\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_009646095.1_ASM964609v1\n",
      "31\n",
      "15.0\n",
      "16.0\n",
      "[]\n",
      "total samples: 31\n",
      "TP: 13\n",
      "FP: 0\n",
      "TN: 16\n",
      "FN: 2\n",
      "accuracy: 0.9354838709677419\n",
      "precision: 1.0\n",
      "recall: 0.8666666666666667\n",
      "F1: 0.9285714285714286\n",
      "GCF_000321415.2_ASM32141v2\n",
      "61\n",
      "29.0\n",
      "32.0\n",
      "[]\n",
      "total samples: 61\n",
      "TP: 25\n",
      "FP: 0\n",
      "TN: 32\n",
      "FN: 4\n",
      "accuracy: 0.9344262295081968\n",
      "precision: 1.0\n",
      "recall: 0.8620689655172413\n",
      "F1: 0.9259259259259259\n",
      "GCF_004851605.1_ASM485160v1\n",
      "30\n",
      "15.0\n",
      "15.0\n",
      "[]\n",
      "total samples: 30\n",
      "TP: 15\n",
      "FP: 0\n",
      "TN: 15\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_001697225.1_ASM169722v1\n",
      "34\n",
      "17.0\n",
      "17.0\n",
      "[16]\n",
      "total samples: 34\n",
      "TP: 16\n",
      "FP: 1\n",
      "TN: 16\n",
      "FN: 1\n",
      "accuracy: 0.9411764705882353\n",
      "precision: 0.9411764705882353\n",
      "recall: 0.9411764705882353\n",
      "F1: 0.9411764705882353\n",
      "GCF_900638485.1_57728_B01\n",
      "13\n",
      "6.0\n",
      "7.0\n",
      "[5]\n",
      "total samples: 13\n",
      "TP: 6\n",
      "FP: 1\n",
      "TN: 6\n",
      "FN: 0\n",
      "accuracy: 0.9230769230769231\n",
      "precision: 0.8571428571428571\n",
      "recall: 1.0\n",
      "F1: 0.923076923076923\n",
      "GCF_002208805.2_ASM220880v2\n",
      "73\n",
      "35.0\n",
      "38.0\n",
      "[35]\n",
      "total samples: 73\n",
      "TP: 34\n",
      "FP: 1\n",
      "TN: 37\n",
      "FN: 1\n",
      "accuracy: 0.9726027397260274\n",
      "precision: 0.9714285714285714\n",
      "recall: 0.9714285714285714\n",
      "F1: 0.9714285714285714\n",
      "GCF_012931585.1_ASM1293158v1\n",
      "79\n",
      "37.0\n",
      "42.0\n",
      "[10, 26, 32]\n",
      "total samples: 79\n",
      "TP: 33\n",
      "FP: 3\n",
      "TN: 39\n",
      "FN: 4\n",
      "accuracy: 0.9113924050632911\n",
      "precision: 0.9166666666666666\n",
      "recall: 0.8918918918918919\n",
      "F1: 0.9041095890410958\n",
      "GCF_001936175.1_ASM193617v1\n",
      "98\n",
      "23.0\n",
      "75.0\n",
      "[29, 43, 68, 72]\n",
      "total samples: 98\n",
      "TP: 22\n",
      "FP: 4\n",
      "TN: 71\n",
      "FN: 1\n",
      "accuracy: 0.9489795918367347\n",
      "precision: 0.8461538461538461\n",
      "recall: 0.9565217391304348\n",
      "F1: 0.8979591836734695\n",
      "GCF_023299185.1_ASM2329918v1\n",
      "42\n",
      "19.0\n",
      "23.0\n",
      "[2, 5, 16, 17, 18]\n",
      "total samples: 42\n",
      "TP: 19\n",
      "FP: 5\n",
      "TN: 18\n",
      "FN: 0\n",
      "accuracy: 0.8809523809523809\n",
      "precision: 0.7916666666666666\n",
      "recall: 1.0\n",
      "F1: 0.8837209302325582\n",
      "GCF_005473905.2_ASM547390v2\n",
      "91\n",
      "44.0\n",
      "47.0\n",
      "[18]\n",
      "total samples: 91\n",
      "TP: 41\n",
      "FP: 1\n",
      "TN: 46\n",
      "FN: 3\n",
      "accuracy: 0.9560439560439561\n",
      "precision: 0.9761904761904762\n",
      "recall: 0.9318181818181818\n",
      "F1: 0.9534883720930233\n",
      "GCF_001685415.1_ASM168541v1\n",
      "21\n",
      "10.0\n",
      "11.0\n",
      "[5]\n",
      "total samples: 21\n",
      "TP: 10\n",
      "FP: 1\n",
      "TN: 10\n",
      "FN: 0\n",
      "accuracy: 0.9523809523809523\n",
      "precision: 0.9090909090909091\n",
      "recall: 1.0\n",
      "F1: 0.9523809523809523\n",
      "GCF_003814405.1_ASM381440v1\n",
      "39\n",
      "18.0\n",
      "21.0\n",
      "[7]\n",
      "total samples: 39\n",
      "TP: 5\n",
      "FP: 1\n",
      "TN: 20\n",
      "FN: 13\n",
      "accuracy: 0.6410256410256411\n",
      "precision: 0.8333333333333334\n",
      "recall: 0.2777777777777778\n",
      "F1: 0.4166666666666667\n",
      "GCF_003711265.1_ASM371126v1\n",
      "25\n",
      "12.0\n",
      "13.0\n",
      "[]\n",
      "total samples: 25\n",
      "TP: 11\n",
      "FP: 0\n",
      "TN: 13\n",
      "FN: 1\n",
      "accuracy: 0.96\n",
      "precision: 1.0\n",
      "recall: 0.9166666666666666\n",
      "F1: 0.9565217391304348\n",
      "GCF_900005615.1_JCM7685\n",
      "67\n",
      "31.0\n",
      "36.0\n",
      "[]\n",
      "total samples: 67\n",
      "TP: 31\n",
      "FP: 0\n",
      "TN: 36\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_017068355.1_ASM1706835v1\n",
      "43\n",
      "19.0\n",
      "24.0\n",
      "[4, 10, 19]\n",
      "total samples: 43\n",
      "TP: 18\n",
      "FP: 3\n",
      "TN: 21\n",
      "FN: 1\n",
      "accuracy: 0.9069767441860465\n",
      "precision: 0.8571428571428571\n",
      "recall: 0.9473684210526315\n",
      "F1: 0.9\n",
      "GCF_008704425.1_ASM870442v1\n",
      "104\n",
      "49.0\n",
      "55.0\n",
      "[28]\n",
      "total samples: 104\n",
      "TP: 48\n",
      "FP: 1\n",
      "TN: 54\n",
      "FN: 1\n",
      "accuracy: 0.9807692307692307\n",
      "precision: 0.9795918367346939\n",
      "recall: 0.9795918367346939\n",
      "F1: 0.9795918367346939\n",
      "GCF_000224965.2_ASM22496v2\n",
      "37\n",
      "18.0\n",
      "19.0\n",
      "[]\n",
      "total samples: 37\n",
      "TP: 15\n",
      "FP: 0\n",
      "TN: 19\n",
      "FN: 3\n",
      "accuracy: 0.918918918918919\n",
      "precision: 1.0\n",
      "recall: 0.8333333333333334\n",
      "F1: 0.9090909090909091\n",
      "GCF_013365475.1_ASM1336547v1\n",
      "13\n",
      "6.0\n",
      "7.0\n",
      "[]\n",
      "total samples: 13\n",
      "TP: 5\n",
      "FP: 0\n",
      "TN: 7\n",
      "FN: 1\n",
      "accuracy: 0.9230769230769231\n",
      "precision: 1.0\n",
      "recall: 0.8333333333333334\n",
      "F1: 0.9090909090909091\n",
      "GCF_001553625.1_ASM155362v1\n",
      "36\n",
      "18.0\n",
      "18.0\n",
      "[]\n",
      "total samples: 36\n",
      "TP: 18\n",
      "FP: 0\n",
      "TN: 18\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_003261055.1_ASM326105v1\n",
      "120\n",
      "56.0\n",
      "64.0\n",
      "[9, 19]\n",
      "total samples: 120\n",
      "TP: 54\n",
      "FP: 2\n",
      "TN: 62\n",
      "FN: 2\n",
      "accuracy: 0.9666666666666667\n",
      "precision: 0.9642857142857143\n",
      "recall: 0.9642857142857143\n",
      "F1: 0.9642857142857143\n",
      "GCF_000092505.1_ASM9250v1\n",
      "68\n",
      "34.0\n",
      "34.0\n",
      "[3, 8, 18, 20, 30]\n",
      "total samples: 68\n",
      "TP: 29\n",
      "FP: 5\n",
      "TN: 29\n",
      "FN: 5\n",
      "accuracy: 0.8529411764705882\n",
      "precision: 0.8529411764705882\n",
      "recall: 0.8529411764705882\n",
      "F1: 0.8529411764705882\n",
      "GCF_000264455.2_ASM26445v2\n",
      "48\n",
      "24.0\n",
      "24.0\n",
      "[8]\n",
      "total samples: 48\n",
      "TP: 22\n",
      "FP: 1\n",
      "TN: 23\n",
      "FN: 2\n",
      "accuracy: 0.9375\n",
      "precision: 0.9565217391304348\n",
      "recall: 0.9166666666666666\n",
      "F1: 0.9361702127659574\n",
      "GCF_000816105.1_ASM81610v1\n",
      "53\n",
      "25.0\n",
      "28.0\n",
      "[18]\n",
      "total samples: 53\n",
      "TP: 24\n",
      "FP: 1\n",
      "TN: 27\n",
      "FN: 1\n",
      "accuracy: 0.9622641509433962\n",
      "precision: 0.96\n",
      "recall: 0.96\n",
      "F1: 0.96\n",
      "GCF_008831385.1_ASM883138v1\n",
      "32\n",
      "16.0\n",
      "16.0\n",
      "[12]\n",
      "total samples: 32\n",
      "TP: 16\n",
      "FP: 1\n",
      "TN: 15\n",
      "FN: 0\n",
      "accuracy: 0.96875\n",
      "precision: 0.9411764705882353\n",
      "recall: 1.0\n",
      "F1: 0.9696969696969697\n",
      "GCF_000317125.1_ASM31712v1\n",
      "116\n",
      "58.0\n",
      "58.0\n",
      "[10, 32, 42, 49]\n",
      "total samples: 116\n",
      "TP: 55\n",
      "FP: 4\n",
      "TN: 54\n",
      "FN: 3\n",
      "accuracy: 0.9396551724137931\n",
      "precision: 0.9322033898305084\n",
      "recall: 0.9482758620689655\n",
      "F1: 0.94017094017094\n",
      "GCF_001660045.1_ASM166004v1\n",
      "116\n",
      "53.0\n",
      "63.0\n",
      "[33]\n",
      "total samples: 116\n",
      "TP: 50\n",
      "FP: 1\n",
      "TN: 62\n",
      "FN: 3\n",
      "accuracy: 0.9655172413793104\n",
      "precision: 0.9803921568627451\n",
      "recall: 0.9433962264150944\n",
      "F1: 0.9615384615384616\n",
      "GCF_018491735.2_ASM1849173v2\n",
      "31\n",
      "14.0\n",
      "17.0\n",
      "[]\n",
      "total samples: 31\n",
      "TP: 9\n",
      "FP: 0\n",
      "TN: 17\n",
      "FN: 5\n",
      "accuracy: 0.8387096774193549\n",
      "precision: 1.0\n",
      "recall: 0.6428571428571429\n",
      "F1: 0.782608695652174\n",
      "GCF_000591055.1_ASM59105v1\n",
      "105\n",
      "52.0\n",
      "53.0\n",
      "[8, 22, 25, 31, 32, 38, 46, 48]\n",
      "total samples: 105\n",
      "TP: 51\n",
      "FP: 8\n",
      "TN: 45\n",
      "FN: 1\n",
      "accuracy: 0.9142857142857143\n",
      "precision: 0.864406779661017\n",
      "recall: 0.9807692307692307\n",
      "F1: 0.918918918918919\n",
      "GCF_023921225.1_ASM2392122v1\n",
      "53\n",
      "25.0\n",
      "28.0\n",
      "[9, 10, 23]\n",
      "total samples: 53\n",
      "TP: 23\n",
      "FP: 3\n",
      "TN: 25\n",
      "FN: 2\n",
      "accuracy: 0.9056603773584906\n",
      "precision: 0.8846153846153846\n",
      "recall: 0.92\n",
      "F1: 0.9019607843137256\n",
      "GCF_014926585.1_ASM1492658v1\n",
      "55\n",
      "27.0\n",
      "28.0\n",
      "[]\n",
      "total samples: 55\n",
      "TP: 27\n",
      "FP: 0\n",
      "TN: 28\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_001866075.3_ASM186607v3\n",
      "214\n",
      "107.0\n",
      "107.0\n",
      "[13, 29, 36, 55, 80, 81, 85, 91, 101, 102]\n",
      "total samples: 214\n",
      "TP: 98\n",
      "FP: 10\n",
      "TN: 97\n",
      "FN: 9\n",
      "accuracy: 0.9112149532710281\n",
      "precision: 0.9074074074074074\n",
      "recall: 0.9158878504672897\n",
      "F1: 0.9116279069767442\n",
      "GCF_000747315.1_ASM74731v1\n",
      "35\n",
      "17.0\n",
      "18.0\n",
      "[5]\n",
      "total samples: 35\n",
      "TP: 17\n",
      "FP: 1\n",
      "TN: 17\n",
      "FN: 0\n",
      "accuracy: 0.9714285714285714\n",
      "precision: 0.9444444444444444\n",
      "recall: 1.0\n",
      "F1: 0.9714285714285714\n",
      "GCF_001886615.1_ASM188661v1\n",
      "26\n",
      "13.0\n",
      "13.0\n",
      "[]\n",
      "total samples: 26\n",
      "TP: 13\n",
      "FP: 0\n",
      "TN: 13\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_014268455.2_ASM1426845v2\n",
      "92\n",
      "42.0\n",
      "50.0\n",
      "[21, 35]\n",
      "total samples: 92\n",
      "TP: 38\n",
      "FP: 2\n",
      "TN: 48\n",
      "FN: 4\n",
      "accuracy: 0.9347826086956522\n",
      "precision: 0.95\n",
      "recall: 0.9047619047619048\n",
      "F1: 0.9268292682926829\n",
      "GCF_009720625.1_ASM972062v1\n",
      "310\n",
      "153.0\n",
      "157.0\n",
      "[18, 27, 51, 106, 109, 132, 145]\n",
      "total samples: 310\n",
      "TP: 145\n",
      "FP: 7\n",
      "TN: 150\n",
      "FN: 8\n",
      "accuracy: 0.9516129032258065\n",
      "precision: 0.9539473684210527\n",
      "recall: 0.9477124183006536\n",
      "F1: 0.9508196721311475\n",
      "GCF_013391105.1_ASM1339110v1\n",
      "147\n",
      "73.0\n",
      "74.0\n",
      "[21, 23, 42, 50, 52, 54, 62]\n",
      "total samples: 147\n",
      "TP: 72\n",
      "FP: 7\n",
      "TN: 67\n",
      "FN: 1\n",
      "accuracy: 0.9455782312925171\n",
      "precision: 0.9113924050632911\n",
      "recall: 0.9863013698630136\n",
      "F1: 0.9473684210526315\n",
      "GCF_900187355.1_51342_E02\n",
      "38\n",
      "18.0\n",
      "20.0\n",
      "[6]\n",
      "total samples: 38\n",
      "TP: 17\n",
      "FP: 1\n",
      "TN: 19\n",
      "FN: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9473684210526315\n",
      "precision: 0.9444444444444444\n",
      "recall: 0.9444444444444444\n",
      "F1: 0.9444444444444444\n",
      "GCF_000953655.1_LHA\n",
      "50\n",
      "25.0\n",
      "25.0\n",
      "[]\n",
      "total samples: 50\n",
      "TP: 21\n",
      "FP: 0\n",
      "TN: 25\n",
      "FN: 4\n",
      "accuracy: 0.92\n",
      "precision: 1.0\n",
      "recall: 0.84\n",
      "F1: 0.9130434782608696\n",
      "GCF_000828915.1_ASM82891v1\n",
      "23\n",
      "10.0\n",
      "13.0\n",
      "[]\n",
      "total samples: 23\n",
      "TP: 10\n",
      "FP: 0\n",
      "TN: 13\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_014217335.1_ASM1421733v1\n",
      "24\n",
      "12.0\n",
      "12.0\n",
      "[]\n",
      "total samples: 24\n",
      "TP: 12\n",
      "FP: 0\n",
      "TN: 12\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_002243665.1_ASM224366v1\n",
      "185\n",
      "81.0\n",
      "104.0\n",
      "[28, 82, 87]\n",
      "total samples: 185\n",
      "TP: 73\n",
      "FP: 3\n",
      "TN: 101\n",
      "FN: 8\n",
      "accuracy: 0.9405405405405406\n",
      "precision: 0.9605263157894737\n",
      "recall: 0.9012345679012346\n",
      "F1: 0.9299363057324841\n",
      "GCF_003265305.2_ASM326530v2\n",
      "16\n",
      "8.0\n",
      "8.0\n",
      "[]\n",
      "total samples: 16\n",
      "TP: 8\n",
      "FP: 0\n",
      "TN: 8\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_003851555.1_ASM385155v1\n",
      "86\n",
      "37.0\n",
      "49.0\n",
      "[13, 36, 39, 48]\n",
      "total samples: 86\n",
      "TP: 35\n",
      "FP: 4\n",
      "TN: 45\n",
      "FN: 2\n",
      "accuracy: 0.9302325581395349\n",
      "precision: 0.8974358974358975\n",
      "recall: 0.9459459459459459\n",
      "F1: 0.9210526315789475\n",
      "GCF_000214355.1_ASM21435v1\n",
      "30\n",
      "15.0\n",
      "15.0\n",
      "[]\n",
      "total samples: 30\n",
      "TP: 13\n",
      "FP: 0\n",
      "TN: 15\n",
      "FN: 2\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 1.0\n",
      "recall: 0.8666666666666667\n",
      "F1: 0.9285714285714286\n",
      "GCF_021278985.1_ASM2127898v1\n",
      "127\n",
      "58.0\n",
      "69.0\n",
      "[7, 14, 56]\n",
      "total samples: 127\n",
      "TP: 51\n",
      "FP: 3\n",
      "TN: 66\n",
      "FN: 7\n",
      "accuracy: 0.9212598425196851\n",
      "precision: 0.9444444444444444\n",
      "recall: 0.8793103448275862\n",
      "F1: 0.9107142857142858\n",
      "GCF_006385595.1_ASM638559v1\n",
      "28\n",
      "13.0\n",
      "15.0\n",
      "[11]\n",
      "total samples: 28\n",
      "TP: 13\n",
      "FP: 1\n",
      "TN: 14\n",
      "FN: 0\n",
      "accuracy: 0.9642857142857143\n",
      "precision: 0.9285714285714286\n",
      "recall: 1.0\n",
      "F1: 0.962962962962963\n",
      "GCF_001718895.1_ASM171889v1\n",
      "111\n",
      "43.0\n",
      "68.0\n",
      "[37]\n",
      "total samples: 111\n",
      "TP: 36\n",
      "FP: 1\n",
      "TN: 67\n",
      "FN: 7\n",
      "accuracy: 0.9279279279279279\n",
      "precision: 0.972972972972973\n",
      "recall: 0.8372093023255814\n",
      "F1: 0.9\n",
      "GCF_900660515.1_50766_E01-3\n",
      "10\n",
      "5.0\n",
      "5.0\n",
      "[]\n",
      "total samples: 10\n",
      "TP: 5\n",
      "FP: 0\n",
      "TN: 5\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_002006355.2_ASM200635v2\n",
      "60\n",
      "17.0\n",
      "43.0\n",
      "[5, 30]\n",
      "total samples: 60\n",
      "TP: 12\n",
      "FP: 2\n",
      "TN: 41\n",
      "FN: 5\n",
      "accuracy: 0.8833333333333333\n",
      "precision: 0.8571428571428571\n",
      "recall: 0.7058823529411765\n",
      "F1: 0.7741935483870968\n",
      "GCF_000266925.1_ASM26692v1\n",
      "30\n",
      "15.0\n",
      "15.0\n",
      "[2, 3]\n",
      "total samples: 30\n",
      "TP: 15\n",
      "FP: 2\n",
      "TN: 13\n",
      "FN: 0\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 0.8823529411764706\n",
      "recall: 1.0\n",
      "F1: 0.9375\n",
      "GCF_000513475.1_Bbla\n",
      "8\n",
      "4.0\n",
      "4.0\n",
      "[]\n",
      "total samples: 8\n",
      "TP: 4\n",
      "FP: 0\n",
      "TN: 4\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_000733715.2_ASM73371v2\n",
      "70\n",
      "33.0\n",
      "37.0\n",
      "[9, 33]\n",
      "total samples: 70\n",
      "TP: 32\n",
      "FP: 2\n",
      "TN: 35\n",
      "FN: 1\n",
      "accuracy: 0.9571428571428572\n",
      "precision: 0.9411764705882353\n",
      "recall: 0.9696969696969697\n",
      "F1: 0.955223880597015\n",
      "GCF_017310015.1_ASM1731001v1\n",
      "41\n",
      "20.0\n",
      "21.0\n",
      "[12, 13, 18]\n",
      "total samples: 41\n",
      "TP: 20\n",
      "FP: 3\n",
      "TN: 18\n",
      "FN: 0\n",
      "accuracy: 0.926829268292683\n",
      "precision: 0.8695652173913043\n",
      "recall: 1.0\n",
      "F1: 0.9302325581395349\n",
      "GCF_000802245.2_ASM80224v2\n",
      "99\n",
      "46.0\n",
      "53.0\n",
      "[]\n",
      "total samples: 99\n",
      "TP: 45\n",
      "FP: 0\n",
      "TN: 53\n",
      "FN: 1\n",
      "accuracy: 0.98989898989899\n",
      "precision: 1.0\n",
      "recall: 0.9782608695652174\n",
      "F1: 0.989010989010989\n",
      "GCF_000017945.1_ASM1794v1\n",
      "15\n",
      "11.0\n",
      "4.0\n",
      "[1]\n",
      "total samples: 15\n",
      "TP: 11\n",
      "FP: 1\n",
      "TN: 3\n",
      "FN: 0\n",
      "accuracy: 0.9333333333333333\n",
      "precision: 0.9166666666666666\n",
      "recall: 1.0\n",
      "F1: 0.9565217391304348\n",
      "GCF_015277875.1_ASM1527787v1\n",
      "30\n",
      "14.0\n",
      "16.0\n",
      "[1]\n",
      "total samples: 30\n",
      "TP: 14\n",
      "FP: 1\n",
      "TN: 15\n",
      "FN: 0\n",
      "accuracy: 0.9666666666666667\n",
      "precision: 0.9333333333333333\n",
      "recall: 1.0\n",
      "F1: 0.9655172413793104\n",
      "GCF_000732925.1_ASM73292v1\n",
      "118\n",
      "49.0\n",
      "69.0\n",
      "[8]\n",
      "total samples: 118\n",
      "TP: 49\n",
      "FP: 1\n",
      "TN: 68\n",
      "FN: 0\n",
      "accuracy: 0.9915254237288136\n",
      "precision: 0.98\n",
      "recall: 1.0\n",
      "F1: 0.98989898989899\n",
      "GCF_020526085.1_ASM2052608v1\n",
      "168\n",
      "67.0\n",
      "101.0\n",
      "[]\n",
      "total samples: 168\n",
      "TP: 31\n",
      "FP: 0\n",
      "TN: 101\n",
      "FN: 36\n",
      "accuracy: 0.7857142857142857\n",
      "precision: 1.0\n",
      "recall: 0.4626865671641791\n",
      "F1: 0.6326530612244898\n",
      "GCF_000147335.1_ASM14733v1\n",
      "199\n",
      "98.0\n",
      "101.0\n",
      "[67, 69, 78]\n",
      "total samples: 199\n",
      "TP: 92\n",
      "FP: 3\n",
      "TN: 98\n",
      "FN: 6\n",
      "accuracy: 0.9547738693467337\n",
      "precision: 0.968421052631579\n",
      "recall: 0.9387755102040817\n",
      "F1: 0.9533678756476685\n",
      "GCF_005877035.1_ASM587703v1\n",
      "45\n",
      "18.0\n",
      "27.0\n",
      "[20]\n",
      "total samples: 45\n",
      "TP: 17\n",
      "FP: 1\n",
      "TN: 26\n",
      "FN: 1\n",
      "accuracy: 0.9555555555555556\n",
      "precision: 0.9444444444444444\n",
      "recall: 0.9444444444444444\n",
      "F1: 0.9444444444444444\n",
      "GCF_010669205.1_ASM1066920v1\n",
      "94\n",
      "45.0\n",
      "49.0\n",
      "[29]\n",
      "total samples: 94\n",
      "TP: 43\n",
      "FP: 1\n",
      "TN: 48\n",
      "FN: 2\n",
      "accuracy: 0.9680851063829787\n",
      "precision: 0.9772727272727273\n",
      "recall: 0.9555555555555556\n",
      "F1: 0.9662921348314608\n",
      "GCF_007856155.1_ASM785615v1\n",
      "83\n",
      "38.0\n",
      "45.0\n",
      "[27, 42]\n",
      "total samples: 83\n",
      "TP: 37\n",
      "FP: 2\n",
      "TN: 43\n",
      "FN: 1\n",
      "accuracy: 0.963855421686747\n",
      "precision: 0.9487179487179487\n",
      "recall: 0.9736842105263158\n",
      "F1: 0.9610389610389611\n",
      "GCF_023547145.1_ASM2354714v1\n",
      "85\n",
      "41.0\n",
      "44.0\n",
      "[4, 7, 30]\n",
      "total samples: 85\n",
      "TP: 35\n",
      "FP: 3\n",
      "TN: 41\n",
      "FN: 6\n",
      "accuracy: 0.8941176470588236\n",
      "precision: 0.9210526315789473\n",
      "recall: 0.8536585365853658\n",
      "F1: 0.8860759493670887\n",
      "GCF_018141545.1_ASM1814154v1\n",
      "14\n",
      "7.0\n",
      "7.0\n",
      "[]\n",
      "total samples: 14\n",
      "TP: 6\n",
      "FP: 0\n",
      "TN: 7\n",
      "FN: 1\n",
      "accuracy: 0.9285714285714286\n",
      "precision: 1.0\n",
      "recall: 0.8571428571428571\n",
      "F1: 0.923076923076923\n",
      "GCF_000023685.1_ASM2368v1\n",
      "19\n",
      "8.0\n",
      "11.0\n",
      "[]\n",
      "total samples: 19\n",
      "TP: 8\n",
      "FP: 0\n",
      "TN: 11\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_013394595.1_ASM1339459v1\n",
      "64\n",
      "32.0\n",
      "32.0\n",
      "[7, 8, 9, 15]\n",
      "total samples: 64\n",
      "TP: 31\n",
      "FP: 4\n",
      "TN: 28\n",
      "FN: 1\n",
      "accuracy: 0.921875\n",
      "precision: 0.8857142857142857\n",
      "recall: 0.96875\n",
      "F1: 0.9253731343283582\n",
      "GCF_002078315.1_ASM207831v1\n",
      "69\n",
      "34.0\n",
      "35.0\n",
      "[20]\n",
      "total samples: 69\n",
      "TP: 22\n",
      "FP: 1\n",
      "TN: 34\n",
      "FN: 12\n",
      "accuracy: 0.8115942028985508\n",
      "precision: 0.9565217391304348\n",
      "recall: 0.6470588235294118\n",
      "F1: 0.7719298245614036\n",
      "GCF_020783375.1_ASM2078337v1\n",
      "80\n",
      "36.0\n",
      "44.0\n",
      "[]\n",
      "total samples: 80\n",
      "TP: 32\n",
      "FP: 0\n",
      "TN: 44\n",
      "FN: 4\n",
      "accuracy: 0.95\n",
      "precision: 1.0\n",
      "recall: 0.8888888888888888\n",
      "F1: 0.9411764705882353\n",
      "GCF_003351545.1_ASM335154v1\n",
      "44\n",
      "21.0\n",
      "23.0\n",
      "[]\n",
      "total samples: 44\n",
      "TP: 19\n",
      "FP: 0\n",
      "TN: 23\n",
      "FN: 2\n",
      "accuracy: 0.9545454545454546\n",
      "precision: 1.0\n",
      "recall: 0.9047619047619048\n",
      "F1: 0.9500000000000001\n",
      "GCF_000166695.1_ASM16669v1\n",
      "91\n",
      "41.0\n",
      "50.0\n",
      "[12, 21, 36, 39]\n",
      "total samples: 91\n",
      "TP: 36\n",
      "FP: 4\n",
      "TN: 46\n",
      "FN: 5\n",
      "accuracy: 0.9010989010989011\n",
      "precision: 0.9\n",
      "recall: 0.8780487804878049\n",
      "F1: 0.888888888888889\n",
      "GCF_002214585.1_ASM221458v1\n",
      "44\n",
      "21.0\n",
      "23.0\n",
      "[]\n",
      "total samples: 44\n",
      "TP: 21\n",
      "FP: 0\n",
      "TN: 23\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_009650215.1_ASM965021v1\n",
      "26\n",
      "13.0\n",
      "13.0\n",
      "[6]\n",
      "total samples: 26\n",
      "TP: 13\n",
      "FP: 1\n",
      "TN: 12\n",
      "FN: 0\n",
      "accuracy: 0.9615384615384616\n",
      "precision: 0.9285714285714286\n",
      "recall: 1.0\n",
      "F1: 0.962962962962963\n",
      "GCF_019722725.1_ASM1972272v1\n",
      "41\n",
      "19.0\n",
      "22.0\n",
      "[7, 17]\n",
      "total samples: 41\n",
      "TP: 18\n",
      "FP: 2\n",
      "TN: 20\n",
      "FN: 1\n",
      "accuracy: 0.926829268292683\n",
      "precision: 0.9\n",
      "recall: 0.9473684210526315\n",
      "F1: 0.9230769230769231\n",
      "GCF_001889125.1_ASM188912v1\n",
      "30\n",
      "14.0\n",
      "16.0\n",
      "[]\n",
      "total samples: 30\n",
      "TP: 13\n",
      "FP: 0\n",
      "TN: 16\n",
      "FN: 1\n",
      "accuracy: 0.9666666666666667\n",
      "precision: 1.0\n",
      "recall: 0.9285714285714286\n",
      "F1: 0.962962962962963\n",
      "GCF_006874765.1_ASM687476v1\n",
      "100\n",
      "48.0\n",
      "52.0\n",
      "[0, 6]\n",
      "total samples: 100\n",
      "TP: 33\n",
      "FP: 2\n",
      "TN: 50\n",
      "FN: 15\n",
      "accuracy: 0.83\n",
      "precision: 0.9428571428571428\n",
      "recall: 0.6875\n",
      "F1: 0.7951807228915663\n",
      "GCF_009931695.1_ASM993169v1\n",
      "94\n",
      "47.0\n",
      "47.0\n",
      "[]\n",
      "total samples: 94\n",
      "TP: 44\n",
      "FP: 0\n",
      "TN: 47\n",
      "FN: 3\n",
      "accuracy: 0.9680851063829787\n",
      "precision: 1.0\n",
      "recall: 0.9361702127659575\n",
      "F1: 0.967032967032967\n",
      "GCF_000196475.1_ASM19647v1\n",
      "86\n",
      "41.0\n",
      "45.0\n",
      "[33]\n",
      "total samples: 86\n",
      "TP: 35\n",
      "FP: 1\n",
      "TN: 44\n",
      "FN: 6\n",
      "accuracy: 0.9186046511627907\n",
      "precision: 0.9722222222222222\n",
      "recall: 0.8536585365853658\n",
      "F1: 0.9090909090909091\n",
      "GCF_003945385.1_ASM394538v1\n",
      "59\n",
      "29.0\n",
      "30.0\n",
      "[5]\n",
      "total samples: 59\n",
      "TP: 28\n",
      "FP: 1\n",
      "TN: 29\n",
      "FN: 1\n",
      "accuracy: 0.9661016949152542\n",
      "precision: 0.9655172413793104\n",
      "recall: 0.9655172413793104\n",
      "F1: 0.9655172413793104\n",
      "GCF_003798325.1_ASM379832v1\n",
      "21\n",
      "10.0\n",
      "11.0\n",
      "[]\n",
      "total samples: 21\n",
      "TP: 9\n",
      "FP: 0\n",
      "TN: 11\n",
      "FN: 1\n",
      "accuracy: 0.9523809523809523\n",
      "precision: 1.0\n",
      "recall: 0.9\n",
      "F1: 0.9473684210526316\n",
      "GCF_018467115.1_ASM1846711v1\n",
      "12\n",
      "2.0\n",
      "10.0\n",
      "[]\n",
      "total samples: 12\n",
      "TP: 2\n",
      "FP: 0\n",
      "TN: 10\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_000212695.1_ASM21269v1\n",
      "46\n",
      "21.0\n",
      "25.0\n",
      "[]\n",
      "total samples: 46\n",
      "TP: 21\n",
      "FP: 0\n",
      "TN: 25\n",
      "FN: 0\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F1: 1.0\n",
      "GCF_008369745.1_ASM836974v1\n",
      "45\n",
      "19.0\n",
      "26.0\n",
      "[8]\n",
      "total samples: 45\n",
      "TP: 19\n",
      "FP: 1\n",
      "TN: 25\n",
      "FN: 0\n",
      "accuracy: 0.9777777777777777\n",
      "precision: 0.95\n",
      "recall: 1.0\n",
      "F1: 0.9743589743589743\n",
      "GCF_008727715.1_ASM872771v1\n",
      "85\n",
      "41.0\n",
      "44.0\n",
      "[20]\n",
      "total samples: 85\n",
      "TP: 40\n",
      "FP: 1\n",
      "TN: 43\n",
      "FN: 1\n",
      "accuracy: 0.9764705882352941\n",
      "precision: 0.975609756097561\n",
      "recall: 0.975609756097561\n",
      "F1: 0.975609756097561\n",
      "GCF_014217765.1_ASM1421776v1\n",
      "60\n",
      "29.0\n",
      "31.0\n",
      "[19, 24]\n",
      "total samples: 60\n",
      "TP: 29\n",
      "FP: 2\n",
      "TN: 29\n",
      "FN: 0\n",
      "accuracy: 0.9666666666666667\n",
      "precision: 0.9354838709677419\n",
      "recall: 1.0\n",
      "F1: 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "accuracies, precisions, recalls, F1s = [], [], [], []\n",
    "\n",
    "def evaluate_by_genome(genomes, find_TP_index = False):\n",
    "    PATH = \"final_ten_fold_cross_validation_models/six_layer_fold_0_genomes.pt\"\n",
    "    ecoli_model = torch.load(PATH)\n",
    "    ecoli_model.eval()\n",
    "\n",
    "    random.seed(5)\n",
    "    torch.manual_seed(5)\n",
    "    for genome in genomes:\n",
    "        print(genome)\n",
    "        test_x = np.array([])\n",
    "        test_y = np.array([])\n",
    "        positive_indices = np.array(positive_filtered_genes_indices[genome]) \n",
    "        negative_indices = np.array(negative_filtered_genes_indices[genome])\n",
    "        if positive_indices.shape[0] == 0 or negative_indices.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        genome_train_coding_embeddings = torch.load('post_processed_data/' + genome + '/coding_train_emb/train_mean.pt')\n",
    "        genome_train_coding_labels = np.ones(genome_train_coding_embeddings.shape[0])[positive_indices]\n",
    "        genome_train_coding_embeddings = genome_train_coding_embeddings[positive_indices]\n",
    "        assert genome_train_coding_embeddings.shape[0] == len(positive_indices)\n",
    "\n",
    "        genome_train_noncoding_embeddings = torch.load('post_processed_data/' + genome + '/noncoding_test_emb/train_mean.pt')\n",
    "        genome_train_noncoding_labels = np.zeros(genome_train_noncoding_embeddings.shape[0])[negative_indices]\n",
    "        genome_train_noncoding_embeddings = genome_train_noncoding_embeddings[negative_indices]\n",
    "        assert genome_train_noncoding_embeddings.shape[0] == len(negative_indices)\n",
    "        \n",
    "        if test_x.shape[0] == 0:\n",
    "            test_x = genome_train_coding_embeddings\n",
    "            test_y = genome_train_coding_labels\n",
    "            test_x = np.concatenate((test_x, genome_train_noncoding_embeddings), axis=0)\n",
    "            test_y = np.concatenate((test_y, genome_train_noncoding_labels), axis=0)\n",
    "\n",
    "        test_output_raw = ecoli_model(torch.Tensor(test_x))\n",
    "        test_output = test_output_raw.round()\n",
    "        \n",
    "        if find_TP_index:\n",
    "            print(len(test_y))\n",
    "            print(sum(test_y))\n",
    "            print(len(test_y) - sum(test_y))\n",
    "            print([i - int(sum(test_y)) for i in range(len(test_output)) if test_output[i] == 1 and test_y[i] == 0])\n",
    "    \n",
    "        accuracy, precision, recall, f1 = perf_measure(list(test_y), list(test_output.detach().numpy()))\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        F1s.append(f1)\n",
    "\n",
    "evaluate_by_genome(genomes[:100], True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807382181505154 0.08080859075054792\n",
      "0.9557485970819304 0.034604080809111544\n",
      "0.6634324374849281 0.2134564478055572\n",
      "0.7589389564582983 0.14515720502173257\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracies), np.std(accuracies))\n",
    "print(np.mean(precisions), np.std(precisions))\n",
    "print(np.mean(recalls), np.std(recalls))\n",
    "print(np.mean(F1s), np.std(F1s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245544, 1280)\n",
      "(26359, 1280)\n",
      "total samples: 26359\n",
      "TP: 6223\n",
      "FP: 7078\n",
      "TN: 6895\n",
      "FN: 6163\n",
      "accuracy: 0.49766683106339393\n",
      "precision: 0.46785955943162166\n",
      "recall: 0.5024220894558372\n",
      "F1: 0.4845252462335033\n",
      "(243767, 1280)\n",
      "(28136, 1280)\n",
      "total samples: 28136\n",
      "TP: 6633\n",
      "FP: 7411\n",
      "TN: 7465\n",
      "FN: 6627\n",
      "accuracy: 0.5010662496445835\n",
      "precision: 0.47230133864995727\n",
      "recall: 0.5002262443438914\n",
      "F1: 0.48586287723410493\n",
      "(241748, 1280)\n",
      "(30155, 1280)\n",
      "total samples: 30155\n",
      "TP: 7217\n",
      "FP: 7974\n",
      "TN: 7853\n",
      "FN: 7111\n",
      "accuracy: 0.49975128502735866\n",
      "precision: 0.47508393127509707\n",
      "recall: 0.5036990508096035\n",
      "F1: 0.48897320369931224\n",
      "(244110, 1280)\n",
      "(27793, 1280)\n",
      "total samples: 27793\n",
      "TP: 6589\n",
      "FP: 7258\n",
      "TN: 7326\n",
      "FN: 6620\n",
      "accuracy: 0.5006656352318929\n",
      "precision: 0.47584314291904384\n",
      "recall: 0.49882655765008704\n",
      "F1: 0.4870638675340035\n",
      "(245386, 1280)\n",
      "(26517, 1280)\n",
      "total samples: 26517\n",
      "TP: 6242\n",
      "FP: 6990\n",
      "TN: 6887\n",
      "FN: 6398\n",
      "accuracy: 0.49511634046083647\n",
      "precision: 0.47173518742442566\n",
      "recall: 0.49382911392405066\n",
      "F1: 0.4825293753865183\n",
      "(244359, 1280)\n",
      "(27544, 1280)\n",
      "total samples: 27544\n",
      "TP: 6556\n",
      "FP: 7297\n",
      "TN: 7312\n",
      "FN: 6379\n",
      "accuracy: 0.503485332558815\n",
      "precision: 0.47325489063740706\n",
      "recall: 0.5068419018167762\n",
      "F1: 0.4894728983126774\n",
      "(246605, 1280)\n",
      "(25298, 1280)\n",
      "total samples: 25298\n",
      "TP: 5991\n",
      "FP: 6729\n",
      "TN: 6604\n",
      "FN: 5974\n",
      "accuracy: 0.4978654439086094\n",
      "precision: 0.47099056603773587\n",
      "recall: 0.5007104053489344\n",
      "F1: 0.4853959894672879\n",
      "(244532, 1280)\n",
      "(27371, 1280)\n",
      "total samples: 27371\n",
      "TP: 6488\n",
      "FP: 7339\n",
      "TN: 7041\n",
      "FN: 6503\n",
      "accuracy: 0.4942822695553688\n",
      "precision: 0.4692268749547986\n",
      "recall: 0.4994226772380879\n",
      "F1: 0.4838541278245954\n",
      "(245299, 1280)\n",
      "(26604, 1280)\n",
      "total samples: 26604\n",
      "TP: 6317\n",
      "FP: 6979\n",
      "TN: 7045\n",
      "FN: 6263\n",
      "accuracy: 0.502255299954894\n",
      "precision: 0.47510529482551145\n",
      "recall: 0.5021462639109698\n",
      "F1: 0.4882516617715258\n",
      "(245777, 1280)\n",
      "(26126, 1280)\n",
      "total samples: 26126\n",
      "TP: 6219\n",
      "FP: 6953\n",
      "TN: 6889\n",
      "FN: 6065\n",
      "accuracy: 0.5017224221082447\n",
      "precision: 0.4721378682052839\n",
      "recall: 0.5062683165092804\n",
      "F1: 0.48860779384035197\n"
     ]
    }
   ],
   "source": [
    "def generate_random_vector(x):\n",
    "    vector = []\n",
    "    for _ in range(x):\n",
    "        element = random.choice([0, 1])\n",
    "        vector.append(element)\n",
    "    return vector\n",
    "\n",
    "random_accuracies, random_precisions, random_recalls, random_f1s = [], [], [], [] \n",
    "\n",
    "random.seed(5)\n",
    "#since data is not completely balanced, we need to add a baseline which predicts labels randomly. \n",
    "for i in range(10):\n",
    "    train_x, train_y, test_x, test_y = create_train_test_data(all_data_folds_embs, all_data_folds_labels, i)\n",
    "    print(train_x.shape)\n",
    "    print(test_x.shape)\n",
    "    random_vector = generate_random_vector(len(test_y))\n",
    "    random_accuracy, random_precision, random_recall, random_f1 = perf_measure(list(test_y), list(random_vector))\n",
    "    random_recalls.append(random_recall)\n",
    "    random_accuracies.append(random_accuracy)\n",
    "    random_precisions.append(random_precision)\n",
    "    random_f1s.append(random_f1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49938771095139967 0.002909228019437151\n",
      "0.47235386543608826 0.0024551607781829036\n",
      "0.501439262100752 0.0036040333950898454\n",
      "0.4864537041303881 0.0022595000503375763\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(random_accuracies), np.std(random_accuracies))\n",
    "print(np.mean(random_precisions), np.std(random_precisions))\n",
    "print(np.mean(random_recalls), np.std(random_recalls))\n",
    "print(np.mean(random_f1s), np.std(random_f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
